{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846bb5ea-708d-473c-87e9-8b02b046d545",
   "metadata": {},
   "source": [
    "# Rough workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c9f235-690a-4dc5-ab07-b0b824f886b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96666667 1.         0.93333333 0.9        1.        ]\n",
      "Mean accuracy: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Output the scores\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8b26a4-0595-49bc-b732-a8e62fd9bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified cross-validation scores: [0.96666667 1.         0.93333333 0.9        1.        ]\n",
      "Mean accuracy: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create a logistic regression model pipeline\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Define stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "# Perform cross-validation with stratified k-fold\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Output the scores\n",
    "print(\"Stratified cross-validation scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dd79517-50a7-4839-bcae-8e862010ad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9600000000000002\n",
      "Mean Precision: 0.9632996632996633\n",
      "Mean Recall: 0.9600000000000002\n",
      "Mean F1-Score: 0.9597984861142755\n",
      "printing before the cross validation\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9333333333333333\n",
      "Recall: 0.9333333333333333\n",
      "F1-Score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create a logistic regression model pipeline\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Define stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "# Output the average metrics\n",
    "print(\"Mean Accuracy:\", sum(accuracies) / len(accuracies))\n",
    "print(\"Mean Precision:\", sum(precisions) / len(precisions))\n",
    "print(\"Mean Recall:\", sum(recalls) / len(recalls))\n",
    "print(\"Mean F1-Score:\", sum(f1_scores) / len(f1_scores))\n",
    "\n",
    "\n",
    "\n",
    "print(\"printing before the cross validation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Create a logistic regression model pipeline\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Output the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9fcf43-1064-4b5a-bb0f-04b1403fef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "F1-Score: 0.96\n",
      "Confusion Matrix:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create a logistic regression model pipeline\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Define stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Generate cross-validated predictions\n",
    "y_pred = cross_val_predict(model, X, y, cv=skf)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred, average='weighted')\n",
    "recall = recall_score(y, y_pred, average='weighted')\n",
    "f1 = f1_score(y, y_pred, average='weighted')\n",
    "confusion_mat = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570a72eb-04c6-4d5a-b2bc-a503e501d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7 2]\n",
      " [2 9]]\n",
      "Accuracy: 0.8\n",
      "\n",
      "Macro Averages:\n",
      "Precision (Macro): 0.797979797979798\n",
      "Recall (Macro): 0.797979797979798\n",
      "F1-Score (Macro): 0.797979797979798\n",
      "\n",
      "Weighted Averages:\n",
      "Precision (Weighted): 0.8\n",
      "Recall (Weighted): 0.8\n",
      "F1-Score (Weighted): 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# True labels\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
    "\n",
    "# Predicted labels\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1-score with macro and weighted averages\n",
    "precision_macro = precision_score(y_true, y_pred, average='macro')\n",
    "recall_macro = recall_score(y_true, y_pred, average='macro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "precision_weighted = precision_score(y_true, y_pred, average='weighted')\n",
    "recall_weighted = recall_score(y_true, y_pred, average='weighted')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nMacro Averages:\")\n",
    "print(\"Precision (Macro):\", precision_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1-Score (Macro):\", f1_macro)\n",
    "\n",
    "print(\"\\nWeighted Averages:\")\n",
    "print(\"Precision (Weighted):\", precision_weighted)\n",
    "print(\"Recall (Weighted):\", recall_weighted)\n",
    "print(\"F1-Score (Weighted):\", f1_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cade80-eed5-4a1f-b0c2-f2da340e604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfsfsdfdzfsfsdfsafsdgsfgsgsdzfsdfsghtrthrfgsgsgdsgdsgdsasdfsdfsagasafdsadfsfsddfszvfregesasgfsfegseasfaeg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
